{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Task 1.ipynb\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# reading data into Data Frame\n",
    "data_frame = pd.read_csv('Task 0 Output.csv')\n",
    "\n",
    "def transform(num):\n",
    "  \"\"\"\n",
    "  This function transforms integers into binary\n",
    "\n",
    "  Parameters:\n",
    "    num (int): an integer number\n",
    "\n",
    "  Returns:\n",
    "    1 if num > 0\n",
    "    0 if num = 0\n",
    "    num otherwise\n",
    "  \"\"\"\n",
    "  if type(num) is int:\n",
    "    if num > 0:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "  return num\n",
    "\n",
    "# apply transformation to numbers in data frame\n",
    "data_frame = data_frame.applymap(transform)\n",
    "\n",
    "# dropping index from Data Frame to call apriori()\n",
    "data_frame.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# dropping date from Data Frame to call apriori()\n",
    "data_frame.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# generating k-itemsets where 1 <= k <= 10\n",
    "all_itemsets = apriori(data_frame, min_support=0.000001, use_colnames=True)\n",
    "\n",
    "# computing length of itemsets to eliminate 1-itemsets\n",
    "all_itemsets['length'] = all_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "\n",
    "# extracting itemsets with at least 2 items\n",
    "two_itemsets = all_itemsets[all_itemsets['length'] >= 2]\n",
    "\n",
    "# selecting 10 itemsets with highest support\n",
    "frequent_itemsets = two_itemsets.sort_values(by='support', ascending=False).head(10)\n",
    "\n",
    "# printing itemsets\n",
    "print(frequent_itemsets)\n",
    "\n",
    "frequent_itemsets.to_csv(\"frequent itemsets.csv\")\n",
    "\n",
    "# generating rules for every itemset\n",
    "rule_df = association_rules(all_itemsets, metric='confidence', min_threshold=0.1)\n",
    "\n",
    "# selecting rules for the itemsets with highest support\n",
    "frequent_itemset_rules = rule_df.sort_values(by='support', ascending=False).head(20)\n",
    "\n",
    "# selecting 5 of the 20 rules with the highest confidence\n",
    "highest_confidence_rules = frequent_itemset_rules.sort_values(by='confidence', ascending=False).head(5)\n",
    "\n",
    "# selecting 5 of the 20 rules with the lowest confidence\n",
    "lowest_confidence_rules = frequent_itemset_rules.sort_values(by='confidence', ascending=True).head(5)\n",
    "\n",
    "# printing rules\n",
    "print(highest_confidence_rules)\n",
    "print(lowest_confidence_rules)\n",
    "\n",
    "highest_confidence_rules.to_csv(\"highest confidence rules.csv\")\n",
    "lowest_confidence_rules.to_csv(\"lowest confidence rules.csv\")\n",
    "\n",
    "# initializing lists of measures of interest\n",
    "odds_ratio_list = []\n",
    "jaccard_list = []\n",
    "cosine_list = []\n",
    "interest_list = []\n",
    "correlation_list = []\n",
    "\n",
    "# computing 5 measures of interest for the highest confidence rules\n",
    "for index, row in highest_confidence_rules.iterrows():\n",
    "  f11 = row['antecedent support'] + row['consequent support']\n",
    "  f10 = row['antecedent support'] + (1 - row['consequent support'])\n",
    "  f01 = (1 - row['antecedent support']) + row['consequent support']\n",
    "  f00 = (1 - row['antecedent support']) + (1 - row['consequent support'])\n",
    "\n",
    "  fp1 = f11 + f01\n",
    "  fp0 = f10 + f00\n",
    "  f1p = f11 + f10\n",
    "  f0p = f01 + f00\n",
    "  N = fp1 + fp0\n",
    "\n",
    "  # computing measures of interest\n",
    "  odds_ratio = (f11 * f00) / (f10 * f01)\n",
    "  jaccard = f11 / (f1p + fp1 - f11)\n",
    "  cosine = f11 / (math.sqrt(f1p * fp1))\n",
    "  interest = (N * f11) / (f1p * fp1)\n",
    "  correlation = ((N * f11) - (f1p * fp1)) / math.sqrt(f1p * fp1 * f0p * fp0)\n",
    "\n",
    "  # adding measures of interest to respective lists\n",
    "  odds_ratio_list.append(odds_ratio)\n",
    "  jaccard_list.append(jaccard)\n",
    "  cosine_list.append(cosine)\n",
    "  interest_list.append(interest)\n",
    "  correlation_list.append(correlation)\n",
    "\n",
    "# appending list of measures of interest to Data Frame\n",
    "highest_confidence_rules['odds ratio'] = odds_ratio_list\n",
    "highest_confidence_rules['jaccard'] = jaccard_list\n",
    "highest_confidence_rules['cosine'] = cosine_list\n",
    "highest_confidence_rules['interest'] = interest_list\n",
    "highest_confidence_rules['correlation'] = correlation_list\n",
    "\n",
    "# displaying updated Data Frame\n",
    "print(highest_confidence_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74afe07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c45a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96729661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
