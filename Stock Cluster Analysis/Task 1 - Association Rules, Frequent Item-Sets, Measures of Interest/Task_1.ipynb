{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "af2caf66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af2caf66",
        "outputId": "5ebe57fb-d469-44f2-ff1b-d979039953d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     support        itemsets  length\n",
            "49  0.483995  (CCOEY, NCBDY)       2\n",
            "40  0.370038      (EA, TTWO)       2\n",
            "19  0.367478    (MSFT, SONY)       2\n",
            "35  0.366197    (ATVI, TTWO)       2\n",
            "29  0.346991    (TTWO, MSFT)       2\n",
            "34  0.344430      (ATVI, EA)       2\n",
            "25  0.332907   (TCEHY, SONY)       2\n",
            "32  0.331626   (TCEHY, MSFT)       2\n",
            "11  0.330346   (NTDOY, MSFT)       2\n",
            "27  0.329065    (ATVI, MSFT)       2\n",
            "   antecedents consequents  antecedent support  consequent support   support  \\\n",
            "79     (NCBDY)     (CCOEY)            0.483995            0.483995  0.483995   \n",
            "78     (CCOEY)     (NCBDY)            0.483995            0.483995  0.483995   \n",
            "60        (EA)      (TTWO)            0.480154            0.505762  0.370038   \n",
            "19      (SONY)      (MSFT)            0.478873            0.517286  0.367478   \n",
            "50      (ATVI)      (TTWO)            0.477593            0.505762  0.366197   \n",
            "\n",
            "    confidence      lift  leverage  conviction  zhangs_metric  \n",
            "79    1.000000  2.066138  0.249744         inf       1.000000  \n",
            "78    1.000000  2.066138  0.249744         inf       1.000000  \n",
            "60    0.770667  1.523774  0.127195    2.155108       0.661224  \n",
            "19    0.767380  1.483474  0.119763    2.075117       0.625388  \n",
            "50    0.766756  1.516042  0.124649    2.118975       0.651575  \n",
            "   antecedents consequents  antecedent support  consequent support   support  \\\n",
            "35      (MSFT)      (ATVI)            0.517286            0.477593  0.329065   \n",
            "3       (MSFT)     (NTDOY)            0.517286            0.512164  0.330346   \n",
            "45      (MSFT)     (TCEHY)            0.517286            0.490397  0.331626   \n",
            "2      (NTDOY)      (MSFT)            0.512164            0.517286  0.330346   \n",
            "39      (MSFT)      (TTWO)            0.517286            0.505762  0.346991   \n",
            "\n",
            "    confidence      lift  leverage  conviction  zhangs_metric  \n",
            "35    0.636139  1.331969  0.082013    1.435731       0.516312  \n",
            "3     0.638614  1.246894  0.065411    1.349903       0.410195  \n",
            "45    0.641089  1.307286  0.077951    1.419860       0.486947  \n",
            "2     0.645000  1.246894  0.065411    1.359759       0.405888  \n",
            "39    0.670792  1.326300  0.085368    1.501295       0.509666  \n",
            "   antecedents consequents  antecedent support  consequent support   support  \\\n",
            "79     (NCBDY)     (CCOEY)            0.483995            0.483995  0.483995   \n",
            "78     (CCOEY)     (NCBDY)            0.483995            0.483995  0.483995   \n",
            "60        (EA)      (TTWO)            0.480154            0.505762  0.370038   \n",
            "19      (SONY)      (MSFT)            0.478873            0.517286  0.367478   \n",
            "50      (ATVI)      (TTWO)            0.477593            0.505762  0.366197   \n",
            "\n",
            "    confidence      lift  leverage  conviction  zhangs_metric  odds ratio  \\\n",
            "79    1.000000  2.066138  0.249744         inf       1.000000    0.998975   \n",
            "78    1.000000  2.066138  0.249744         inf       1.000000    0.998975   \n",
            "60    0.770667  1.523774  0.127195    2.155108       0.661224    1.000458   \n",
            "19    0.767380  1.483474  0.119763    2.075117       0.625388    1.001463   \n",
            "50    0.766756  1.516042  0.124649    2.118975       0.651575    1.000517   \n",
            "\n",
            "     jaccard    cosine  interest  correlation  \n",
            "79  0.326143  0.491867  0.999735    -0.000256  \n",
            "78  0.326143  0.491867  0.999735    -0.000256  \n",
            "60  0.330189  0.496495  1.000116     0.000114  \n",
            "19  0.332479  0.499130  1.000367     0.000365  \n",
            "50  0.329614  0.495854  1.000131     0.000129  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Task 1.ipynb\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import math\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# reading data into Data Frame\n",
        "data_frame = pd.read_csv('Task 0 Output.csv')\n",
        "\n",
        "def transform(num):\n",
        "  \"\"\"\n",
        "  This function transforms integers into binary\n",
        "\n",
        "  Parameters:\n",
        "    num (int): an integer number\n",
        "\n",
        "  Returns:\n",
        "    1 if num > 0\n",
        "    0 if num = 0\n",
        "    num otherwise\n",
        "  \"\"\"\n",
        "  if type(num) is int:\n",
        "    if num > 0:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  return num\n",
        "\n",
        "# apply transformation to numbers in data frame\n",
        "data_frame = data_frame.applymap(transform)\n",
        "\n",
        "# dropping index from Data Frame to call apriori()\n",
        "data_frame.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# dropping date from Data Frame to call apriori()\n",
        "data_frame.drop('Date', axis=1, inplace=True)\n",
        "\n",
        "# generating k-itemsets where 1 <= k <= 10\n",
        "all_itemsets = apriori(data_frame, min_support=0.000001, use_colnames=True)\n",
        "\n",
        "# computing length of itemsets to eliminate 1-itemsets\n",
        "all_itemsets['length'] = all_itemsets['itemsets'].apply(lambda x: len(x))\n",
        "\n",
        "# extracting itemsets with at least 2 items\n",
        "two_itemsets = all_itemsets[all_itemsets['length'] >= 2]\n",
        "\n",
        "# selecting 10 itemsets with highest support\n",
        "frequent_itemsets = two_itemsets.sort_values(by='support', ascending=False).head(10)\n",
        "\n",
        "# printing itemsets\n",
        "print(frequent_itemsets)\n",
        "\n",
        "frequent_itemsets.to_csv(\"frequent itemsets.csv\")\n",
        "\n",
        "# generating rules for every itemset\n",
        "rule_df = association_rules(all_itemsets, metric='confidence', min_threshold=0.1)\n",
        "\n",
        "# selecting rules for the itemsets with highest support\n",
        "frequent_itemset_rules = rule_df.sort_values(by='support', ascending=False).head(20)\n",
        "\n",
        "# selecting 5 of the 20 rules with the highest confidence\n",
        "highest_confidence_rules = frequent_itemset_rules.sort_values(by='confidence', ascending=False).head(5)\n",
        "\n",
        "# selecting 5 of the 20 rules with the lowest confidence\n",
        "lowest_confidence_rules = frequent_itemset_rules.sort_values(by='confidence', ascending=True).head(5)\n",
        "\n",
        "# printing rules\n",
        "print(highest_confidence_rules)\n",
        "print(lowest_confidence_rules)\n",
        "\n",
        "highest_confidence_rules.to_csv(\"highest confidence rules.csv\")\n",
        "lowest_confidence_rules.to_csv(\"lowest confidence rules.csv\")\n",
        "\n",
        "# initializing lists of measures of interest\n",
        "odds_ratio_list = []\n",
        "jaccard_list = []\n",
        "cosine_list = []\n",
        "interest_list = []\n",
        "correlation_list = []\n",
        "\n",
        "# computing 5 measures of interest for the highest confidence rules\n",
        "for index, row in highest_confidence_rules.iterrows():\n",
        "  f11 = row['antecedent support'] + row['consequent support']\n",
        "  f10 = row['antecedent support'] + (1 - row['consequent support'])\n",
        "  f01 = (1 - row['antecedent support']) + row['consequent support']\n",
        "  f00 = (1 - row['antecedent support']) + (1 - row['consequent support'])\n",
        "\n",
        "  fp1 = f11 + f01\n",
        "  fp0 = f10 + f00\n",
        "  f1p = f11 + f10\n",
        "  f0p = f01 + f00\n",
        "  N = fp1 + fp0\n",
        "\n",
        "  # computing measures of interest\n",
        "  odds_ratio = (f11 * f00) / (f10 * f01)\n",
        "  jaccard = f11 / (f1p + fp1 - f11)\n",
        "  cosine = f11 / (math.sqrt(f1p * fp1))\n",
        "  interest = (N * f11) / (f1p * fp1)\n",
        "  correlation = ((N * f11) - (f1p * fp1)) / math.sqrt(f1p * fp1 * f0p * fp0)\n",
        "\n",
        "  # adding measures of interest to respective lists\n",
        "  odds_ratio_list.append(odds_ratio)\n",
        "  jaccard_list.append(jaccard)\n",
        "  cosine_list.append(cosine)\n",
        "  interest_list.append(interest)\n",
        "  correlation_list.append(correlation)\n",
        "\n",
        "# appending list of measures of interest to Data Frame\n",
        "highest_confidence_rules['odds ratio'] = odds_ratio_list\n",
        "highest_confidence_rules['jaccard'] = jaccard_list\n",
        "highest_confidence_rules['cosine'] = cosine_list\n",
        "highest_confidence_rules['interest'] = interest_list\n",
        "highest_confidence_rules['correlation'] = correlation_list\n",
        "\n",
        "# displaying updated Data Frame\n",
        "print(highest_confidence_rules)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}